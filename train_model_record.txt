classification
V0——————10W训练集，1W验证集
SBert_best_2021-08-30
2021-08-30 11:08:49,143 train_sentence_bert.py [line:97] INFO train_acc: 0.9993------val_acc:0.9930------best_acc:0.9930
2021-08-30 12:03:55,118 train_sentence_bert.py [line:97] INFO train_acc: 0.9998------val_acc:0.9922------best_acc:0.9930

V1——————20W训练集，2W验证集
20W_SBert_best_new2021-08-30
2021-08-30 17:40:29,142 train_sentence_bert.py [line:99] INFO val_acc:0.9985------best_acc:0.9985

regression
V1——————20W训练集，2W验证集 标注分别为0和1
re_val_loss: 226.7432------re_loss_min:226.7432







验证集准确率和最佳阈值：
best_cls_threshold: 0.7600 -------best_cls_acc:0.9970
best_reg_threshold: 0.0500 -------best_reg_acc:0.5314


验证集准确率和最佳阈值：
best_cls_threshold: 0.7600 -------best_cls_acc:0.9970
best_reg_threshold: 0.0700 -------best_reg_acc:0.5262


集内和集外 安装最佳阈值和相似度来计算
tokenization: 100%|█| 23028/23028 [00:03<00:00, 60
embedding: 100%|██████████████████████████████| 360/360 [00:13<00:00, 27.12it/s]
inside acc:0.9887
tokenization: 100%|█| 1145/1145 [00:00<00:00, 6246
embedding: 100%|████████████████████████████████| 18/18 [00:00<00:00, 29.19it/s]
outside acc:0.9118
****************************************************************************************************
tokenization: 100%|█| 23028/23028 [00:03<00:00, 59
embedding: 100%|██████████████████████████████| 360/360 [00:12<00:00, 27.98it/s]
inside acc:0.9887
tokenization: 100%|█| 1145/1145 [00:00<00:00, 6252
embedding: 100%|████████████████████████████████| 18/18 [00:00<00:00, 29.09it/s]
outside acc:0.3694






向量打分实验进展如下：
方案一：采用Sentence-bert训练分类任务，数据集20W训练集2W验证集，同一类别的为正样本对，不同类别的为负样本对；
方案二：采用Sentence-bert训练回归任务，数据集20W训练集2W验证集，在同一行的标注1.0，一级和二级分类相同的标注0.5，同一不同二标注0.3；一级和二级分类都不同标注0；
方案一验证集上的准确率：0.9985  方案二在验证集上的平均loss为0.011

在验证集上计算cos similarity 依据标注的分类label 选取最佳的阈值  验证集准确率和最佳阈值：
best_cls_threshold: 0.7600 -------best_cls_acc:0.9970
best_reg_threshold: 0.0500 -------best_reg_acc:0.5314

从验证集句子对的相似度分布来看，我个人认为方案一的更为合理；方案二的有很多值不合理，看起来很凌乱，没有明显的规律；
用0820上海库的数据分为库内和库外来测试
方案一——库内：inside acc:0.9887 库外outside acc:0.9118————————————库内应该为100%的 错误的情况都是一个问题多个答案，语料有问题
方案二——库内：inside acc:0.9887 库外outside acc:0.3694————————————库内应该为100%的 错误的情况都是一个问题多个答案，语料有问题
库外相差巨大，是方案二的相似度度量很有问题

综上，我认为需要采用分类方案来训练模型————标注数据更加容易简单，目前的量化指标比方案二好；同时后续优化也可以进一步优化，比较难搞的badcase可以之间采用分类任务，不是采用计算相似度，使得方案可控
后续的优化，可以在语料清洗上————尽可能使得同一类问法确实是相似的；非同一类的不是相似的

还有一个集外的测试效果对比————五类意图推荐结果
个人大致看了一眼觉得方案一的结果更为合理————可以找业务那边帮忙核查一遍




V2——————20W训练集，2W验证集
20W_SBert_best_new2021-08-31
2021-08-30 17:40:29,142 train_sentence_bert.py [line:99] INFO val_acc:0.9990------best_acc:0.9991

best_cls_threshold: 0.7900 -------best_cls_acc:0.9983

0831验证集shanghai————inside和outside
tokenization: 100%|█| 22095/22095 [00:03<00:00, 60
embedding: 100%|██████████████████████████████| 346/346 [00:12<00:00, 26.89it/s]
inside acc:0.9891
tokenization: 100%|█| 1099/1099 [00:00<00:00, 6086
embedding: 100%|████████████████████████████████| 18/18 [00:00<00:00, 29.08it/s]
outside acc:0.9063




最新结果对比
best_sbert_threshold: 0.7600 -------best_sbert_acc:0.9970
best_simcsesup_threshold: 0.5900 -------best_simcsesup_acc:0.9889
best_simcseunsup_threshold: 0.4200 -------best_simcseunsup_acc:0.8865